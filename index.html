<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Operating Systems Concepts - Visual Guide</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            color: #333;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }

        .header {
            text-align: center;
            color: white;
            margin-bottom: 40px;
        }

        .header h1 {
            font-size: 3rem;
            margin-bottom: 10px;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }

        .header p {
            font-size: 1.2rem;
            opacity: 0.9;
        }

        .categories {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 30px;
            margin-bottom: 40px;
        }

        .category-card {
            background: white;
            border-radius: 15px;
            padding: 25px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.2);
            transition: transform 0.3s ease, box-shadow 0.3s ease;
            cursor: pointer;
        }

        .category-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 15px 40px rgba(0,0,0,0.3);
        }

        .category-card h3 {
            color: #4a5568;
            font-size: 1.5rem;
            margin-bottom: 15px;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .category-icon {
            font-size: 2rem;
        }

        .topic-list {
            list-style: none;
        }

        .topic-list li {
            padding: 8px 0;
            border-bottom: 1px solid #e2e8f0;
            color: #666;
            transition: color 0.2s ease;
        }

        .topic-list li:hover {
            color: #4299e1;
        }

        .topic-list li:last-child {
            border-bottom: none;
        }

        .modal {
            display: none;
            position: fixed;
            z-index: 1000;
            left: 0;
            top: 0;
            width: 100%;
            height: 100%;
            background-color: rgba(0,0,0,0.8);
            backdrop-filter: blur(5px);
        }

        .modal-content {
            background-color: white;
            margin: 2% auto;
            padding: 30px;
            border-radius: 15px;
            width: 90%;
            max-width: 1000px;
            max-height: 90vh;
            overflow-y: auto;
            position: relative;
        }

        .close {
            color: #aaa;
            float: right;
            font-size: 28px;
            font-weight: bold;
            cursor: pointer;
            position: absolute;
            right: 20px;
            top: 15px;
        }

        .close:hover {
            color: #000;
        }

        .concept-diagram {
            margin: 20px 0;
            padding: 20px;
            background: #f8f9fa;
            border-radius: 10px;
            border-left: 4px solid #4299e1;
        }

        .diagram-title {
            font-size: 1.3rem;
            font-weight: bold;
            color: #2d3748;
            margin-bottom: 15px;
        }

        .visual-element {
            display: flex;
            align-items: center;
            justify-content: center;
            margin: 15px 0;
            flex-wrap: wrap;
            gap: 15px;
        }

        .process-box, .memory-block, .queue-item, .file-block {
            padding: 15px 20px;
            border-radius: 8px;
            font-weight: bold;
            text-align: center;
            min-width: 80px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }

        .process-box {
            background: linear-gradient(135deg, #ff6b6b, #ee5a52);
            color: white;
        }

        .memory-block {
            background: linear-gradient(135deg, #4ecdc4, #44a08d);
            color: white;
        }

        .queue-item {
            background: linear-gradient(135deg, #45b7d1, #96c93d);
            color: white;
        }

        .file-block {
            background: linear-gradient(135deg, #f093fb, #f5576c);
            color: white;
        }

        .arrow {
            font-size: 1.5rem;
            color: #666;
        }

        .algorithm-steps {
            background: #e6fffa;
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
        }

        .algorithm-steps h4 {
            color: #2c7a7b;
            margin-bottom: 10px;
        }

        .algorithm-steps ol {
            margin-left: 20px;
        }

        .algorithm-steps li {
            margin: 5px 0;
            color: #2d3748;
        }

        .detailed-explanation {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 8px;
            margin: 15px 0;
            border-left: 4px solid #007bff;
        }

        .detailed-explanation h4 {
            color: #2c7a7b;
            margin: 20px 0 10px 0;
            font-size: 1.1rem;
        }

        .detailed-explanation h5 {
            color: #4a5568;
            margin: 15px 0 8px 0;
            font-size: 1rem;
        }

        .code-block {
            background: #2d3748;
            color: #e2e8f0;
            padding: 15px;
            border-radius: 6px;
            font-family: 'Courier New', monospace;
            font-size: 0.9rem;
            line-height: 1.4;
            overflow-x: auto;
            margin: 10px 0;
            white-space: pre;
        }

        .detailed-explanation ul {
            margin: 10px 0 10px 20px;
        }

        .detailed-explanation ol {
            margin: 10px 0 10px 20px;
        }

        .detailed-explanation li {
            margin: 8px 0;
            line-height: 1.5;
        }

        .detailed-explanation p {
            margin: 12px 0;
            line-height: 1.6;
        }

        .timeline {
            display: flex;
            align-items: center;
            gap: 10px;
            margin: 20px 0;
            overflow-x: auto;
            padding: 10px;
        }

        .time-slot {
            min-width: 60px;
            height: 40px;
            display: flex;
            align-items: center;
            justify-content: center;
            border-radius: 5px;
            font-weight: bold;
            color: white;
            font-size: 0.9rem;
        }

        @media (max-width: 768px) {
            .header h1 {
                font-size: 2rem;
            }
            
            .categories {
                grid-template-columns: 1fr;
            }
            
            .modal-content {
                width: 95%;
                margin: 5% auto;
                padding: 20px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ–¥ï¸ Operating Systems Concepts</h1>
            <p>Comprehensive Interactive Guide to Core OS Topics</p>
            <p style="font-size: 1rem; margin-top: 10px; opacity: 0.8;">
                Deep dive into OS fundamentals with detailed explanations, examples, and visual aids
            </p>
        </div>

        <div class="categories">
            <div class="category-card" onclick="openModal('process-management')">
                <h3><span class="category-icon">âš™ï¸</span>Process Management</h3>
                <ul class="topic-list">
                    <li>Process Concept</li>
                    <li>System Call</li>
                    <li>Inter Process Communication</li>
                    <li>Multi Threading</li>
                </ul>
            </div>

            <div class="category-card" onclick="openModal('cpu-scheduling')">
                <h3><span class="category-icon">ğŸ“Š</span>CPU Scheduling</h3>
                <ul class="topic-list">
                    <li>FCFS Scheduling</li>
                    <li>SJF & SRTF Scheduling</li>
                    <li>Round Robin Scheduling</li>
                    <li>Priority Scheduling</li>
                    <li>Multi Level Queue</li>
                </ul>
            </div>

            <div class="category-card" onclick="openModal('memory-management')">
                <h3><span class="category-icon">ğŸ’¾</span>Memory Management</h3>
                <ul class="topic-list">
                    <li>Memory Allocation</li>
                    <li>Paging & Segmentation</li>
                    <li>Virtual Memory</li>
                    <li>Page Replacement</li>
                </ul>
            </div>

            <div class="category-card" onclick="openModal('deadlock')">
                <h3><span class="category-icon">ğŸ”’</span>Deadlock Management</h3>
                <ul class="topic-list">
                    <li>Deadlock Introduction</li>
                    <li>Deadlock Conditions</li>
                    <li>Prevention & Avoidance</li>
                    <li>Detection & Recovery</li>
                </ul>
            </div>

            <div class="category-card" onclick="openModal('io-filesystem')">
                <h3><span class="category-icon">ğŸ“</span>I/O & File Systems</h3>
                <ul class="topic-list">
                    <li>I/O Subsystem</li>
                    <li>File System Structure</li>
                    <li>File Allocation Methods</li>
                    <li>Directory Structure</li>
                </ul>
            </div>
        </div>
    </div>

    <!-- Modals for each category -->
    <div id="process-management" class="modal">
        <div class="modal-content">
            <span class="close" onclick="closeModal('process-management')">&times;</span>
            <h2>âš™ï¸ Process Management - Comprehensive Guide</h2>
            
            <div class="concept-diagram">
                <div class="diagram-title">1. Process Concept - What is a Process?</div>
                <div class="detailed-explanation">
                    <p><strong>Definition:</strong> A process is a program in execution. It's more than just code - it includes the current activity, program counter, stack, data section, and heap.</p>
                    
                    <h4>ğŸ—ï¸ Process Structure in Memory:</h4>
                    <pre class="code-block">
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â† High Memory
â”‚      Stack      â”‚ (Local variables, function calls)
â”‚        â†“        â”‚ (Grows downward)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                 â”‚ (Free space)
â”‚        â†‘        â”‚ (Grows upward)
â”‚      Heap       â”‚ (Dynamic memory allocation)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Data Section  â”‚ (Global & static variables)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Text Section  â”‚ (Program code)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â† Low Memory
                    </pre>
                    
                    <h4>ğŸ”„ Program vs Process:</h4>
                    <ul>
                        <li><strong>Program:</strong> Passive entity (executable file on disk)</li>
                        <li><strong>Process:</strong> Active entity (program loaded in memory and executing)</li>
                        <li><strong>Example:</strong> notepad.exe (program) â†’ Running Notepad window (process)</li>
                    </ul>
                </div>
            </div>

            <div class="concept-diagram">
                <div class="diagram-title">2. Process States - The Process Lifecycle</div>
                <div class="detailed-explanation">
                    <h4>ğŸ”„ State Transition Diagram:</h4>
                    <pre class="code-block">
    NEW â”€â”€â”€â”€â”€â”€â†’ READY â”€â”€â”€â”€â”€â”€â†’ RUNNING
     â”‚            â†‘              â”‚
     â”‚            â”‚              â†“
     â”‚            â”‚         WAITING/BLOCKED
     â”‚            â”‚              â”‚
     â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                           â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ TERMINATED â†â”€â”€â”€â”€â”˜
                    </pre>
                    
                    <h4>ğŸ“‹ Detailed State Descriptions:</h4>
                    <ul>
                        <li><strong>NEW:</strong> Process is being created, PCB allocated</li>
                        <li><strong>READY:</strong> Process loaded in memory, waiting for CPU</li>
                        <li><strong>RUNNING:</strong> Process is currently executing on CPU</li>
                        <li><strong>WAITING/BLOCKED:</strong> Process waiting for I/O or event</li>
                        <li><strong>TERMINATED:</strong> Process finished execution, resources being freed</li>
                    </ul>
                    
                    <h4>ğŸ¯ Real-world Example:</h4>
                    <p><strong>Opening a Word Document:</strong></p>
                    <ol>
                        <li><strong>NEW:</strong> Double-click Word icon â†’ OS creates process</li>
                        <li><strong>READY:</strong> Word loaded in memory, waiting for CPU time</li>
                        <li><strong>RUNNING:</strong> Word interface appears, you can type</li>
                        <li><strong>BLOCKED:</strong> Saving file â†’ waiting for disk I/O</li>
                        <li><strong>READY:</strong> Save complete â†’ ready to run again</li>
                        <li><strong>TERMINATED:</strong> Close Word â†’ process ends</li>
                    </ol>
                </div>
            </div>

            <div class="concept-diagram">
                <div class="diagram-title">3. System Calls - Gateway to OS Services</div>
                <div class="detailed-explanation">
                    <p><strong>Definition:</strong> System calls provide interface between user programs and OS kernel services.</p>
                    
                    <h4>ğŸ”§ System Call Mechanism:</h4>
                    <pre class="code-block">
User Program
     â”‚ (Library call: printf())
     â†“
Standard Library
     â”‚ (System call: write())
     â†“
Kernel Mode â†â”€â”€â”€ Trap/Interrupt
     â”‚
OS Kernel
     â”‚ (Execute system call)
     â†“
Hardware
                    </pre>
                    
                    <h4>ğŸ“š Categories with Examples:</h4>
                    
                    <h5>1ï¸âƒ£ Process Control:</h5>
                    <ul>
                        <li><strong>fork():</strong> Create child process</li>
                        <li><strong>exec():</strong> Replace process image</li>
                        <li><strong>wait():</strong> Wait for child process</li>
                        <li><strong>exit():</strong> Terminate process</li>
                    </ul>
                    
                    <h5>2ï¸âƒ£ File Management:</h5>
                    <ul>
                        <li><strong>open():</strong> Open file for reading/writing</li>
                        <li><strong>read():</strong> Read data from file</li>
                        <li><strong>write():</strong> Write data to file</li>
                        <li><strong>close():</strong> Close file descriptor</li>
                    </ul>
                    
                    <h5>3ï¸âƒ£ Device Management:</h5>
                    <ul>
                        <li><strong>ioctl():</strong> Device-specific operations</li>
                        <li><strong>mount():</strong> Mount file system</li>
                        <li><strong>umount():</strong> Unmount file system</li>
                    </ul>
                    
                    <h4>ğŸ’» Code Example (C):</h4>
                    <pre class="code-block">
#include &lt;unistd.h&gt;
#include &lt;sys/wait.h&gt;

int main() {
    pid_t pid = fork();  // System call to create child
    
    if (pid == 0) {
        // Child process
        execl("/bin/ls", "ls", "-l", NULL);  // Replace with ls
    } else {
        // Parent process
        wait(NULL);  // Wait for child to complete
        printf("Child process finished\n");
    }
    return 0;
}
                    </pre>
                </div>
            </div>

            <div class="concept-diagram">
                <div class="diagram-title">4. Inter Process Communication (IPC)</div>
                <div class="detailed-explanation">
                    <p><strong>Why IPC?</strong> Processes need to communicate and synchronize for cooperation and data sharing.</p>
                    
                    <h4>ğŸ”„ IPC Mechanisms:</h4>
                    
                    <h5>1ï¸âƒ£ Shared Memory:</h5>
                    <pre class="code-block">
Process A                    Process B
    â”‚                           â”‚
    â†“                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Memory  â”‚ â†â”€â”€ Shared â”€â”€â†’ â”‚ Memory  â”‚
â”‚ Space   â”‚     Region     â”‚ Space   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    </pre>
                    <p><strong>Advantages:</strong> Fast, efficient for large data</p>
                    <p><strong>Disadvantages:</strong> Synchronization issues, complex</p>
                    
                    <h5>2ï¸âƒ£ Message Passing:</h5>
                    <pre class="code-block">
Process A â”€â”€â†’ [Message Queue] â”€â”€â†’ Process B
Process C â”€â”€â†’ [    Kernel    ] â”€â”€â†’ Process D
                    </pre>
                    <p><strong>Advantages:</strong> No synchronization issues, works across networks</p>
                    <p><strong>Disadvantages:</strong> Slower due to kernel involvement</p>
                    
                    <h5>3ï¸âƒ£ Pipes:</h5>
                    <pre class="code-block">
# Anonymous Pipe (Parent-Child)
Parent â”€â”€â†’ [Pipe] â”€â”€â†’ Child

# Named Pipe (FIFO)
Process A â”€â”€â†’ [Named Pipe] â”€â”€â†’ Process B
                    </pre>
                    
                    <h5>4ï¸âƒ£ Sockets:</h5>
                    <pre class="code-block">
Client Process â†â”€â”€â†’ [Socket] â†â”€â”€â†’ Server Process
   (Local)                         (Remote)
                    </pre>
                    
                    <h4>ğŸ¯ Real-world Examples:</h4>
                    <ul>
                        <li><strong>Browser & Plugins:</strong> Shared memory for fast rendering</li>
                        <li><strong>Email Client:</strong> Message queues for sending emails</li>
                        <li><strong>Shell Commands:</strong> Pipes (ls | grep .txt)</li>
                        <li><strong>Web Services:</strong> Sockets for client-server communication</li>
                    </ul>
                </div>
            </div>

            <div class="concept-diagram">
                <div class="diagram-title">5. Multi-Threading - Lightweight Processes</div>
                <div class="detailed-explanation">
                    <p><strong>Thread:</strong> Lightweight process that shares memory space with other threads in the same process.</p>
                    
                    <h4>ğŸ§µ Process vs Thread:</h4>
                    <pre class="code-block">
PROCESS                    THREAD
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Stack       â”‚       â”‚   Thread 1      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤       â”‚   Stack         â”‚
â”‚     Heap        â”‚       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â†â”€â”€â†’ â”‚   Thread 2      â”‚
â”‚   Data Section  â”‚       â”‚   Stack         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Text Section   â”‚       â”‚   Shared        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚   Heap & Data   â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    </pre>
                    
                    <h4>ğŸ¯ Thread Benefits:</h4>
                    <ul>
                        <li><strong>Responsiveness:</strong> UI remains responsive during background tasks</li>
                        <li><strong>Resource Sharing:</strong> Threads share memory, files, code</li>
                        <li><strong>Economy:</strong> Creating threads is cheaper than processes</li>
                        <li><strong>Scalability:</strong> Utilize multiple CPU cores</li>
                    </ul>
                    
                    <h4>ğŸ”„ Thread Types:</h4>
                    <ul>
                        <li><strong>User Threads:</strong> Managed by thread library (faster)</li>
                        <li><strong>Kernel Threads:</strong> Managed by OS (more features)</li>
                        <li><strong>Hybrid:</strong> Combination of both approaches</li>
                    </ul>
                    
                    <h4>ğŸ’» Threading Example (Java):</h4>
                    <pre class="code-block">
class DownloadThread extends Thread {
    public void run() {
        // Download file in background
        downloadFile("large_file.zip");
    }
}

class UIThread extends Thread {
    public void run() {
        // Keep UI responsive
        updateProgressBar();
    }
}

// Main application
DownloadThread downloader = new DownloadThread();
UIThread ui = new UIThread();
downloader.start();  // Start background download
ui.start();          // Keep UI active
                    </pre>
                    
                    <h4>âš ï¸ Threading Challenges:</h4>
                    <ul>
                        <li><strong>Race Conditions:</strong> Multiple threads accessing shared data</li>
                        <li><strong>Deadlocks:</strong> Threads waiting for each other</li>
                        <li><strong>Synchronization:</strong> Coordinating thread execution</li>
                    </ul>
                </div>
            </div>
        </div>
    </div>

    <div id="cpu-scheduling" class="modal">
        <div class="modal-content">
            <span class="close" onclick="closeModal('cpu-scheduling')">&times;</span>
            <h2>ğŸ“Š CPU Scheduling Algorithms - Complete Guide</h2>
            
            <div class="concept-diagram">
                <div class="diagram-title">CPU Scheduling Introduction</div>
                <div class="detailed-explanation">
                    <p><strong>Purpose:</strong> CPU scheduling determines which process gets CPU time and for how long, maximizing CPU utilization and system throughput.</p>
                    
                    <h4>ğŸ¯ Scheduling Criteria:</h4>
                    <ul>
                        <li><strong>CPU Utilization:</strong> Keep CPU busy (40-90%)</li>
                        <li><strong>Throughput:</strong> Number of processes completed per time unit</li>
                        <li><strong>Turnaround Time:</strong> Time from submission to completion</li>
                        <li><strong>Waiting Time:</strong> Time spent in ready queue</li>
                        <li><strong>Response Time:</strong> Time from request to first response</li>
                    </ul>
                    
                    <h4>ğŸ”„ Preemptive vs Non-Preemptive:</h4>
                    <ul>
                        <li><strong>Preemptive:</strong> OS can interrupt running process</li>
                        <li><strong>Non-Preemptive:</strong> Process runs until completion or blocks</li>
                    </ul>
                </div>
            </div>

            <div class="concept-diagram">
                <div class="diagram-title">1. First Come First Serve (FCFS)</div>
                <div class="detailed-explanation">
                    <p><strong>Algorithm:</strong> Processes are executed in the order they arrive in the ready queue.</p>
                    
                    <h4>ğŸ”§ How it Works:</h4>
                    <pre class="code-block">
Ready Queue: [P1] â†’ [P2] â†’ [P3] â†’ [P4]
Execution:   P1 runs completely, then P2, then P3, then P4
                    </pre>
                    
                    <h4>ğŸ“Š Example:</h4>
                    <pre class="code-block">
Process | Arrival Time | Burst Time
P1      |      0       |     8
P2      |      1       |     4  
P3      |      2       |     9
P4      |      3       |     5

Gantt Chart:
0    8    12    21    26
|P1  |P2  |P3   |P4  |

Waiting Time:
P1: 0, P2: 7, P3: 10, P4: 18
Average Waiting Time: (0+7+10+18)/4 = 8.75
                    </pre>
                    
                    <h4>âœ… Advantages:</h4>
                    <ul>
                        <li>Simple to understand and implement</li>
                        <li>No starvation - every process gets CPU</li>
                        <li>Fair in terms of arrival order</li>
                    </ul>
                    
                    <h4>âŒ Disadvantages:</h4>
                    <ul>
                        <li><strong>Convoy Effect:</strong> Short processes wait for long ones</li>
                        <li>Poor average waiting time</li>
                        <li>Not suitable for interactive systems</li>
                    </ul>
                    
                    <h4>ğŸ¯ Best Use Case:</h4>
                    <p>Batch processing systems where processes have similar execution times.</p>
                </div>
            </div>

            <div class="concept-diagram">
                <div class="diagram-title">2. Shortest Job First (SJF)</div>
                <div class="detailed-explanation">
                    <p><strong>Algorithm:</strong> Select the process with the smallest burst time. Optimal for minimizing average waiting time.</p>
                    
                    <h4>ğŸ”§ Two Variants:</h4>
                    <h5>Non-Preemptive SJF:</h5>
                    <pre class="code-block">
Process | Arrival Time | Burst Time
P1      |      0       |     8
P2      |      1       |     4  
P3      |      2       |     9
P4      |      3       |     5

Execution Order: P1(0) â†’ P2(4) â†’ P4(5) â†’ P3(9)
Gantt Chart:
0    8    12    17    26
|P1  |P2  |P4  |P3   |
                    </pre>
                    
                    <h5>Preemptive SJF (SRTF - Shortest Remaining Time First):</h5>
                    <pre class="code-block">
Same processes as above:

0-1: P1 runs (remaining: 7)
1-2: P2 arrives (burst: 4 < 7), P2 runs (remaining: 3)
2-3: P3 arrives (burst: 9 > 3), P2 continues (remaining: 2)
3-5: P4 arrives (burst: 5 > 2), P2 continues, completes
5-8: P4 runs (burst: 5 < 7), P4 completes
8-15: P1 resumes and completes
15-24: P3 runs and completes

Gantt Chart:
0  1    5    8    15    24
|P1|P2  |P4  |P1  |P3   |
                    </pre>
                    
                    <h4>âœ… Advantages:</h4>
                    <ul>
                        <li>Optimal average waiting time</li>
                        <li>Good for batch systems</li>
                        <li>Minimizes total completion time</li>
                    </ul>
                    
                    <h4>âŒ Disadvantages:</h4>
                    <ul>
                        <li><strong>Starvation:</strong> Long processes may never execute</li>
                        <li>Requires knowledge of burst time (prediction needed)</li>
                        <li>Not practical for interactive systems</li>
                    </ul>
                    
                    <h4>ğŸ”® Burst Time Prediction:</h4>
                    <pre class="code-block">
Ï„(n+1) = Î± Ã— t(n) + (1-Î±) Ã— Ï„(n)

Where:
Ï„(n+1) = predicted next burst time
t(n) = actual last burst time  
Î± = smoothing factor (0 â‰¤ Î± â‰¤ 1)
                    </pre>
                </div>
            </div>

            <div class="concept-diagram">
                <div class="diagram-title">3. Round Robin (RR)</div>
                <div class="detailed-explanation">
                    <p><strong>Algorithm:</strong> Each process gets a fixed time slice (quantum). When quantum expires, process goes to end of ready queue.</p>
                    
                    <h4>ğŸ”§ How it Works:</h4>
                    <pre class="code-block">
Time Quantum = 3

Process | Arrival Time | Burst Time
P1      |      0       |     8
P2      |      1       |     4  
P3      |      2       |     9

Round 1: P1(3), P2(3), P3(3)
Round 2: P1(3), P2(1), P3(3)  
Round 3: P1(2), P3(3)

Gantt Chart:
0   3   6   9   12  13  16  18  21
|P1 |P2 |P3 |P1 |P2|P3 |P1|P3 |

Waiting Time:
P1: (0) + (9-3) + (16-12) = 10
P2: (3-1) + (12-6) = 8  
P3: (6-2) + (13-9) + (18-16) = 10
Average: (10+8+10)/3 = 9.33
                    </pre>
                    
                    <h4>â° Time Quantum Selection:</h4>
                    <ul>
                        <li><strong>Too Small:</strong> High context switching overhead</li>
                        <li><strong>Too Large:</strong> Becomes FCFS</li>
                        <li><strong>Rule of Thumb:</strong> 80% of processes should complete within one quantum</li>
                    </ul>
                    
                    <h4>âœ… Advantages:</h4>
                    <ul>
                        <li>Fair allocation of CPU time</li>
                        <li>Good response time for interactive systems</li>
                        <li>No starvation</li>
                        <li>Preemptive nature prevents monopolization</li>
                    </ul>
                    
                    <h4>âŒ Disadvantages:</h4>
                    <ul>
                        <li>Higher average turnaround time than SJF</li>
                        <li>Context switching overhead</li>
                        <li>Performance depends on quantum size</li>
                    </ul>
                    
                    <h4>ğŸ¯ Best Use Case:</h4>
                    <p>Time-sharing systems, interactive applications, multi-user environments.</p>
                </div>
            </div>

            <div class="concept-diagram">
                <div class="diagram-title">4. Priority Scheduling</div>
                <div class="detailed-explanation">
                    <p><strong>Algorithm:</strong> Each process has a priority. CPU allocated to highest priority process.</p>
                    
                    <h4>ğŸ”§ Priority Assignment:</h4>
                    <ul>
                        <li><strong>Internal:</strong> Memory requirements, file usage, CPU/I/O ratio</li>
                        <li><strong>External:</strong> User importance, payment, department</li>
                        <li><strong>Static:</strong> Priority fixed throughout execution</li>
                        <li><strong>Dynamic:</strong> Priority changes during execution</li>
                    </ul>
                    
                    <h4>ğŸ“Š Example (Lower number = Higher priority):</h4>
                    <pre class="code-block">
Process | Arrival | Burst | Priority
P1      |    0    |   8   |    3
P2      |    1    |   4   |    1    (Highest)
P3      |    2    |   9   |    4    (Lowest)
P4      |    3    |   5   |    2

Non-Preemptive Priority:
0-8: P1 runs (no other process available)
8-12: P2 runs (priority 1, highest among P2,P3,P4)
12-17: P4 runs (priority 2)
17-26: P3 runs (priority 4)

Preemptive Priority:
0-1: P1 runs
1-5: P2 arrives (priority 1 > 3), P2 runs
5-8: P2 completes, P1 resumes
8-13: P4 runs (priority 2 > 3)
13-20: P1 resumes
20-29: P3 runs
                    </pre>
                    
                    <h4>âš ï¸ Starvation Problem:</h4>
                    <p><strong>Problem:</strong> Low priority processes may never execute if high priority processes keep arriving.</p>
                    
                    <h4>ğŸ’¡ Solution - Aging:</h4>
                    <pre class="code-block">
Aging Algorithm:
1. Increase priority of waiting processes over time
2. Example: Priority = Priority - (waiting_time / aging_factor)
3. Eventually, even low priority processes get high priority
                    </pre>
                    
                    <h4>âœ… Advantages:</h4>
                    <ul>
                        <li>Important processes get CPU first</li>
                        <li>Flexible - can be preemptive or non-preemptive</li>
                        <li>Good for real-time systems</li>
                    </ul>
                    
                    <h4>âŒ Disadvantages:</h4>
                    <ul>
                        <li>Starvation of low priority processes</li>
                        <li>Priority inversion problem</li>
                        <li>Difficult to determine optimal priorities</li>
                    </ul>
                </div>
            </div>

            <div class="concept-diagram">
                <div class="diagram-title">5. Multi-Level Queue Scheduling</div>
                <div class="detailed-explanation">
                    <p><strong>Algorithm:</strong> Processes are classified into different queues based on their characteristics. Each queue has its own scheduling algorithm.</p>
                    
                    <h4>ğŸ—ï¸ Queue Structure:</h4>
                    <pre class="code-block">
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â† Highest Priority
â”‚  System Processes   â”‚ (Priority Scheduling)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Interactive Processesâ”‚ (Round Robin, q=2)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  
â”‚   Batch Processes   â”‚ (FCFS)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Student Processes  â”‚ (FCFS)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â† Lowest Priority
                    </pre>
                    
                    <h4>ğŸ”„ Queue Scheduling:</h4>
                    <ul>
                        <li><strong>Fixed Priority:</strong> Higher queue always gets CPU first</li>
                        <li><strong>Time Slicing:</strong> Each queue gets percentage of CPU time</li>
                    </ul>
                    
                    <h4>ğŸ“Š Example with Time Slicing:</h4>
                    <pre class="code-block">
Queue Allocation:
- System: 50% CPU time
- Interactive: 30% CPU time  
- Batch: 15% CPU time
- Student: 5% CPU time

If system queue is empty, interactive gets CPU
If both system and interactive empty, batch gets CPU
                    </pre>
                    
                    <h4>âœ… Advantages:</h4>
                    <ul>
                        <li>Different algorithms for different process types</li>
                        <li>System processes get priority</li>
                        <li>Good separation of concerns</li>
                    </ul>
                    
                    <h4>âŒ Disadvantages:</h4>
                    <ul>
                        <li>Starvation of lower priority queues</li>
                        <li>Inflexible - processes can't move between queues</li>
                        <li>Complex to implement</li>
                    </ul>
                </div>
            </div>

            <div class="concept-diagram">
                <div class="diagram-title">6. Multi-Level Feedback Queue</div>
                <div class="detailed-explanation">
                    <p><strong>Algorithm:</strong> Processes can move between queues based on their behavior. Adaptive scheduling that learns from process characteristics.</p>
                    
                    <h4>ğŸ”„ Queue Movement Rules:</h4>
                    <pre class="code-block">
Queue 0: RR with quantum = 8
Queue 1: RR with quantum = 16  
Queue 2: FCFS

Rules:
1. New process enters Queue 0
2. If process uses full quantum â†’ demoted to next queue
3. If process blocks for I/O â†’ promoted to higher queue
4. If process completes within quantum â†’ stays in same queue
                    </pre>
                    
                    <h4>ğŸ“Š Example Process Movement:</h4>
                    <pre class="code-block">
Process P1 (CPU-intensive):
Queue 0: Uses full quantum (8) â†’ Demoted to Queue 1
Queue 1: Uses full quantum (16) â†’ Demoted to Queue 2  
Queue 2: Runs with FCFS until completion

Process P2 (I/O-intensive):
Queue 0: Blocks for I/O after 3 units â†’ Stays in Queue 0
Queue 0: Blocks for I/O after 5 units â†’ Stays in Queue 0
Continues in Queue 0 due to frequent I/O
                    </pre>
                    
                    <h4>ğŸ¯ Adaptive Behavior:</h4>
                    <ul>
                        <li><strong>Interactive processes:</strong> Stay in high priority queues (frequent I/O)</li>
                        <li><strong>CPU-bound processes:</strong> Move to lower priority queues</li>
                        <li><strong>Aging:</strong> Processes in lower queues eventually get promoted</li>
                    </ul>
                    
                    <h4>âœ… Advantages:</h4>
                    <ul>
                        <li>Adapts to process behavior</li>
                        <li>Good response time for interactive processes</li>
                        <li>Prevents starvation through aging</li>
                        <li>No need to know process characteristics in advance</li>
                    </ul>
                    
                    <h4>âŒ Disadvantages:</h4>
                    <ul>
                        <li>Complex to implement and tune</li>
                        <li>High overhead due to queue management</li>
                        <li>Difficult to predict performance</li>
                    </ul>
                    
                    <h4>ğŸ† Real-world Usage:</h4>
                    <p>Used in modern operating systems like Windows, Linux, and macOS with various modifications.</p>
                </div>
            </div>

            <div class="concept-diagram">
                <div class="diagram-title">7. Additional Scheduling Algorithms</div>
                <div class="detailed-explanation">
                    <h4>ğŸ”„ Highest Response Ratio Next (HRRN):</h4>
                    <pre class="code-block">
Response Ratio = (Waiting Time + Burst Time) / Burst Time

Select process with highest response ratio
Prevents starvation while favoring shorter processes
                    </pre>
                    
                    <h4>ğŸ“Š Longest Job First (LJF):</h4>
                    <ul>
                        <li>Opposite of SJF - select longest process first</li>
                        <li>Poor average waiting time</li>
                        <li>Rarely used in practice</li>
                    </ul>
                    
                    <h4>â° Longest Remaining Time First (LRTF):</h4>
                    <ul>
                        <li>Preemptive version of LJF</li>
                        <li>Worst possible scheduling algorithm</li>
                        <li>Used mainly for academic comparison</li>
                    </ul>
                    
                    <h4>ğŸ¯ Algorithm Comparison Summary:</h4>
                    <pre class="code-block">
Algorithm    | Preemptive | Starvation | Overhead | Use Case
FCFS         | No         | No         | Low      | Batch
SJF          | Optional   | Yes        | Medium   | Batch  
RR           | Yes        | No         | High     | Interactive
Priority     | Optional   | Yes        | Medium   | Real-time
MLQ          | Yes        | Yes        | High     | Mixed
MLFQ         | Yes        | No         | Very High| General
                    </pre>
                </div>
            </div>
        </div>
    </div>

    <div id="memory-management" class="modal">
        <div class="modal-content">
            <span class="close" onclick="closeModal('memory-management')">&times;</span>
            <h2>ğŸ’¾ Memory Management - Complete Guide</h2>
            
            <div class="concept-diagram">
                <div class="diagram-title">Memory Management Introduction</div>
                <div class="detailed-explanation">
                    <p><strong>Purpose:</strong> Memory management handles allocation and deallocation of memory space to processes, ensuring efficient utilization and protection.</p>
                    
                    <h4>ğŸ¯ Key Objectives:</h4>
                    <ul>
                        <li><strong>Allocation:</strong> Provide memory space to processes</li>
                        <li><strong>Protection:</strong> Prevent processes from accessing each other's memory</li>
                        <li><strong>Sharing:</strong> Allow controlled sharing of memory between processes</li>
                        <li><strong>Efficiency:</strong> Minimize memory waste and access time</li>
                    </ul>
                    
                    <h4>ğŸ—ï¸ Memory Hierarchy:</h4>
                    <pre class="code-block">
CPU Registers    â†â”€â”€ Fastest, Smallest
Cache Memory     â†â”€â”€ Very Fast, Small
Main Memory      â†â”€â”€ Fast, Medium
Secondary Storage â†â”€â”€ Slow, Large
                    </pre>
                </div>
            </div>

            <div class="concept-diagram">
                <div class="diagram-title">1. Memory Allocation Strategies</div>
                <div class="detailed-explanation">
                    <p><strong>Problem:</strong> How to allocate memory blocks to processes when multiple free blocks are available?</p>
                    
                    <h4>ğŸ”§ Allocation Algorithms:</h4>
                    
                    <h5>1ï¸âƒ£ First Fit:</h5>
                    <pre class="code-block">
Memory Layout: [100K] [50K] [200K] [300K] [75K]
                Free   Used   Free   Free   Used

Request: 150K
Result: Allocated in 200K block
Remaining: [100K] [50K] [50K] [300K] [75K]
                   Free   Used  Free   Free   Used
                    </pre>
                    <p><strong>Algorithm:</strong> Scan from beginning, allocate first suitable block</p>
                    <p><strong>Advantage:</strong> Fast allocation</p>
                    <p><strong>Disadvantage:</strong> Creates small fragments at beginning</p>
                    
                    <h5>2ï¸âƒ£ Best Fit:</h5>
                    <pre class="code-block">
Memory Layout: [100K] [50K] [200K] [300K] [75K]
                Free   Used   Free   Free   Used

Request: 150K
Search all blocks: 100K(too small), 200K(fits), 300K(fits)
Result: Allocated in 200K block (smallest that fits)
Remaining: [100K] [50K] [50K] [300K] [75K]
                   Free   Used  Free   Free   Used
                    </pre>
                    <p><strong>Algorithm:</strong> Find smallest block that fits</p>
                    <p><strong>Advantage:</strong> Minimizes wasted space</p>
                    <p><strong>Disadvantage:</strong> Slow search, creates tiny fragments</p>
                    
                    <h5>3ï¸âƒ£ Worst Fit:</h5>
                    <pre class="code-block">
Memory Layout: [100K] [50K] [200K] [300K] [75K]
                Free   Used   Free   Free   Used

Request: 150K
Search all blocks: Find largest (300K)
Result: Allocated in 300K block
Remaining: [100K] [50K] [200K] [150K] [75K]
                   Free   Used   Free   Free   Used
                    </pre>
                    <p><strong>Algorithm:</strong> Find largest available block</p>
                    <p><strong>Advantage:</strong> Leaves larger remaining fragments</p>
                    <p><strong>Disadvantage:</strong> Wastes large blocks quickly</p>
                    
                    <h4>ğŸ“Š Performance Comparison:</h4>
                    <pre class="code-block">
Algorithm  | Speed | Memory Utilization | Fragmentation
First Fit  | Fast  | Good              | High at start
Best Fit   | Slow  | Best              | Many tiny holes
Worst Fit  | Slow  | Poor              | Fewer large holes
                    </pre>
                </div>
            </div>

            <div class="concept-diagram">
                <div class="diagram-title">2. Paging System - Fixed-Size Allocation</div>
                <div class="detailed-explanation">
                    <p><strong>Concept:</strong> Divide physical memory into fixed-size frames and logical memory into same-size pages.</p>
                    
                    <h4>ğŸ—ï¸ Paging Structure:</h4>
                    <pre class="code-block">
LOGICAL MEMORY (Process View)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” Page 0 (4KB)
â”‚ Code    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Page 1 (4KB)  
â”‚ Data    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Page 2 (4KB)
â”‚ Stack   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PHYSICAL MEMORY (OS View)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” Frame 0 (4KB) â† Page 2
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Frame 1 (4KB) â† Other Process
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Frame 2 (4KB) â† Page 0
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Frame 3 (4KB) â† Page 1
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    </pre>
                    
                    <h4>ğŸ”„ Address Translation:</h4>
                    <pre class="code-block">
Logical Address: [Page Number | Offset]
                     12 bits   | 12 bits (4KB pages)

Example: Logical Address 8196 (0x2004)
Page Number: 8196 / 4096 = 2
Offset: 8196 % 4096 = 4

Page Table: Page 2 â†’ Frame 0
Physical Address: Frame 0 + Offset 4 = 4
                    </pre>
                    
                    <h4>ğŸ“‹ Page Table Structure:</h4>
                    <pre class="code-block">
Page Table Entry (PTE):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”
â”‚Frame Number â”‚Validâ”‚Dirtyâ”‚Ref  â”‚Prot â”‚Otherâ”‚
â”‚   20 bits   â”‚ 1   â”‚ 1   â”‚ 1   â”‚ 3   â”‚ 6   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜

Valid: Page is in memory
Dirty: Page has been modified
Reference: Page has been accessed
Protection: Read/Write/Execute permissions
                    </pre>
                    
                    <h4>âœ… Advantages of Paging:</h4>
                    <ul>
                        <li><strong>No External Fragmentation:</strong> All frames are same size</li>
                        <li><strong>Easy Allocation:</strong> Any free frame can be used</li>
                        <li><strong>Protection:</strong> Each page can have different permissions</li>
                        <li><strong>Sharing:</strong> Multiple processes can share pages</li>
                    </ul>
                    
                    <h4>âŒ Disadvantages:</h4>
                    <ul>
                        <li><strong>Internal Fragmentation:</strong> Last page may be partially used</li>
                        <li><strong>Memory Overhead:</strong> Page table storage</li>
                        <li><strong>Translation Overhead:</strong> Extra memory access for page table</li>
                    </ul>
                </div>
            </div>

            <div class="concept-diagram">
                <div class="diagram-title">3. Virtual Memory - Beyond Physical Limits</div>
                <div class="detailed-explanation">
                    <p><strong>Concept:</strong> Allow processes to use more memory than physically available by storing some pages on disk.</p>
                    
                    <h4>ğŸ¯ Key Benefits:</h4>
                    <ul>
                        <li><strong>Large Address Space:</strong> Process can be larger than physical memory</li>
                        <li><strong>Multiprogramming:</strong> More processes can run simultaneously</li>
                        <li><strong>Isolation:</strong> Each process has its own virtual address space</li>
                        <li><strong>Efficiency:</strong> Only needed pages are loaded</li>
                    </ul>
                    
                    <h4>ğŸ”„ Demand Paging Process:</h4>
                    <pre class="code-block">
1. Process accesses page
2. Check page table
3. If page in memory â†’ Access directly
4. If page not in memory â†’ Page Fault
5. OS loads page from disk to memory
6. Update page table
7. Restart instruction
                    </pre>
                    
                    <h4>âš¡ Page Fault Handling:</h4>
                    <pre class="code-block">
Page Fault Occurs:
1. Hardware traps to OS
2. OS checks if address is valid
3. Find free frame (or select victim)
4. Read page from disk to frame
5. Update page table
6. Restart faulting instruction

Time Cost:
- Memory access: ~100 nanoseconds
- Disk access: ~10 milliseconds
- Ratio: 1:100,000 (disk is 100,000x slower!)
                    </pre>
                    
                    <h4>ğŸ“Š Virtual Memory Example:</h4>
                    <pre class="code-block">
Process Virtual Space: 1GB (256K pages)
Physical Memory: 256MB (64K frames)
Page Size: 4KB

Process can use 1GB virtual space
Only active pages (maybe 10-20MB) in physical memory
Rest stored on disk (swap space)
                    </pre>
                    
                    <h4>âš ï¸ Thrashing:</h4>
                    <p><strong>Problem:</strong> System spends more time paging than executing</p>
                    <pre class="code-block">
Thrashing Scenario:
1. Too many processes in memory
2. Each process gets few frames
3. Frequent page faults occur
4. CPU utilization drops
5. OS thinks it needs more processes
6. Adds more processes â†’ Worse thrashing

Solution: Working Set Model, Page Fault Frequency
                    </pre>
                </div>
            </div>

            <div class="concept-diagram">
                <div class="diagram-title">4. Page Replacement Algorithms</div>
                <div class="detailed-explanation">
                    <p><strong>Problem:</strong> When memory is full and a new page needs to be loaded, which page should be removed?</p>
                    
                    <h4>ğŸ”„ FIFO (First In, First Out):</h4>
                    <pre class="code-block">
Reference String: 7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 2
Frames: 3

Step | Pages in Memory | Page Fault?
  7  |      [7]        |     Yes
  0  |    [7,0]        |     Yes  
  1  |   [7,0,1]       |     Yes
  2  |   [0,1,2]       |     Yes (remove 7)
  0  |   [0,1,2]       |     No
  3  |   [1,2,3]       |     Yes (remove 0)
  0  |   [2,3,0]       |     Yes (remove 1)
  4  |   [3,0,4]       |     Yes (remove 2)
  2  |   [0,4,2]       |     Yes (remove 3)
  3  |   [4,2,3]       |     Yes (remove 0)

Total Page Faults: 9
                    </pre>
                    
                    <h4>ğŸ§  LRU (Least Recently Used):</h4>
                    <pre class="code-block">
Same Reference String: 7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 2

Step | Pages in Memory | Last Used Time | Page Fault?
  7  |      [7]        |      [1]       |     Yes
  0  |    [7,0]        |     [1,2]      |     Yes
  1  |   [7,0,1]       |    [1,2,3]     |     Yes
  2  |   [0,1,2]       |    [2,3,4]     |     Yes (remove 7)
  0  |   [0,1,2]       |    [5,3,4]     |     No (update 0)
  3  |   [0,3,2]       |    [5,6,4]     |     Yes (remove 1)
  0  |   [0,3,2]       |    [7,6,4]     |     No
  4  |   [0,3,4]       |    [7,6,8]     |     Yes (remove 2)

Total Page Faults: 6 (Better than FIFO!)
                    </pre>
                    
                    <h4>ğŸ¯ Optimal Algorithm:</h4>
                    <pre class="code-block">
Replace page that will be used farthest in future
(Theoretical - requires future knowledge)

Same Reference String:
Step | Pages | Next Use | Replace
  2  |[7,0,1]|[âˆ,4,âˆ]  | Remove 7 (never used)
  3  |[0,1,2]|[4,âˆ,6]  | Remove 1 (used farthest)

Total Page Faults: 5 (Optimal)
                    </pre>
                    
                    <h4>â° Clock Algorithm (Second Chance):</h4>
                    <pre class="code-block">
Circular buffer with reference bits:

    â”Œâ”€[0,R=1]â”€â”
    â”‚         â”‚
[1,R=0]     [2,R=1]
    â”‚         â”‚
    â””â”€[3,R=0]â”€â”˜
         â†‘
      pointer

Algorithm:
1. Check page at pointer
2. If R=0: Replace this page
3. If R=1: Set R=0, advance pointer
4. Repeat until R=0 page found

Approximates LRU with less overhead
                    </pre>
                    
                    <h4>ğŸ“Š Algorithm Comparison:</h4>
                    <pre class="code-block">
Algorithm | Page Faults | Overhead | Implementation
FIFO      |    High     |   Low    |    Simple
LRU       |    Low      |   High   |    Complex
Optimal   |   Lowest    |    -     |  Impossible
Clock     |   Medium    |   Low    |    Simple
                    </pre>
                </div>
            </div>

            <div class="concept-diagram">
                <div class="diagram-title">5. Memory Compaction and Segmentation</div>
                <div class="detailed-explanation">
                    <h4>ğŸ”§ Memory Compaction:</h4>
                    <p><strong>Problem:</strong> External fragmentation creates unusable memory holes</p>
                    
                    <pre class="code-block">
Before Compaction:
[Process A][Free 50K][Process B][Free 30K][Process C][Free 100K]

After Compaction:
[Process A][Process B][Process C][Free 180K]

Benefits: Combines small holes into large block
Cost: Must relocate processes (expensive)
                    </pre>
                    
                    <h4>ğŸ—‚ï¸ Segmentation:</h4>
                    <p><strong>Concept:</strong> Divide program into logical segments (code, data, stack)</p>
                    
                    <pre class="code-block">
Segment Table:
Segment | Base Address | Limit | Permissions
Code    |    1000      | 2000  |   R-X
Data    |    4000      | 1500  |   RW-
Stack   |    8000      | 1000  |   RW-

Logical Address: [Segment Number | Offset]
Physical Address: Base[Segment] + Offset

Advantages:
- Logical division matches program structure
- Different protection for different segments
- Easy sharing of code segments

Disadvantages:
- External fragmentation
- Complex memory management
                    </pre>
                    
                    <h4>ğŸ”„ Paged Segmentation:</h4>
                    <p><strong>Hybrid Approach:</strong> Combine benefits of both paging and segmentation</p>
                    
                    <pre class="code-block">
Logical Address: [Segment | Page | Offset]

1. Use segment number to find segment table entry
2. Use page number to find page table entry  
3. Use offset to find exact location in frame

Benefits:
- No external fragmentation (paging)
- Logical program structure (segmentation)
- Protection and sharing capabilities

Used in: Intel x86 architecture
                    </pre>
                </div>
            </div>
        </div>
    </div>

    <div id="deadlock" class="modal">
        <div class="modal-content">
            <span class="close" onclick="closeModal('deadlock')">&times;</span>
            <h2>ğŸ”’ Deadlock Management - Complete Guide</h2>
            
            <div class="concept-diagram">
                <div class="diagram-title">Deadlock Introduction</div>
                <div class="detailed-explanation">
                    <p><strong>Definition:</strong> A deadlock is a situation where two or more processes are blocked forever, waiting for each other to release resources.</p>
                    
                    <h4>ğŸ¯ Real-World Analogy:</h4>
                    <p>Imagine two cars approaching a narrow bridge from opposite directions. Each car enters the bridge but cannot proceed because the other car is blocking the way. Neither can back up, creating a deadlock.</p>
                    
                    <h4>ğŸ’» Computer Example:</h4>
                    <pre class="code-block">
Process P1:                Process P2:
1. Lock(Resource A)        1. Lock(Resource B)
2. Lock(Resource B) â†â”€â”€â”€â”€â”€â”€â”€â”€ 2. Lock(Resource A) â† DEADLOCK!
3. Use both resources     3. Use both resources
4. Unlock(Resource B)     4. Unlock(Resource A)
5. Unlock(Resource A)     5. Unlock(Resource B)
                    </pre>
                </div>
            </div>

            <div class="concept-diagram">
                <div class="diagram-title">1. Coffman Conditions - Four Necessary Conditions</div>
                <div class="detailed-explanation">
                    <p><strong>Key Insight:</strong> ALL four conditions must be present simultaneously for deadlock to occur.</p>
                    
                    <h4>1ï¸âƒ£ Mutual Exclusion:</h4>
                    <p><strong>Definition:</strong> At least one resource must be held in a non-shareable mode.</p>
                    <pre class="code-block">
Example: Printer Resource
- Only one process can use printer at a time
- Cannot be shared simultaneously
- If P1 is printing, P2 must wait

Non-Example: Read-only file
- Multiple processes can read simultaneously
- No mutual exclusion â†’ No deadlock possible
                    </pre>
                    
                    <h4>2ï¸âƒ£ Hold and Wait:</h4>
                    <p><strong>Definition:</strong> A process must be holding at least one resource and waiting for additional resources held by other processes.</p>
                    <pre class="code-block">
Process P1:
- Currently holds: Scanner
- Waiting for: Printer (held by P2)

Process P2:
- Currently holds: Printer  
- Waiting for: Scanner (held by P1)

Both processes hold resources while waiting!
                    </pre>
                    
                    <h4>3ï¸âƒ£ No Preemption:</h4>
                    <p><strong>Definition:</strong> Resources cannot be forcibly removed from processes. They must be released voluntarily.</p>
                    <pre class="code-block">
Examples of Non-Preemptible Resources:
- Mutex locks
- Semaphores
- I/O devices (printer, scanner)
- Database records

Examples of Preemptible Resources:
- CPU (can be preempted by scheduler)
- Memory pages (can be swapped out)
                    </pre>
                    
                    <h4>4ï¸âƒ£ Circular Wait:</h4>
                    <p><strong>Definition:</strong> A circular chain of processes exists where each process waits for a resource held by the next process in the chain.</p>
                    <pre class="code-block">
Circular Wait Chain:
P1 â†’ waits for â†’ R2 (held by P2)
P2 â†’ waits for â†’ R3 (held by P3)  
P3 â†’ waits for â†’ R1 (held by P1)

Visual Representation:
    P1 â†â”€â”€â”€ R1
    â”‚        â†‘
    â†“        â”‚
    R2 â”€â”€â”€â†’ P3
    â†‘        â”‚
    â”‚        â†“
    P2 â†â”€â”€â”€ R3
                    </pre>
                </div>
            </div>

            <div class="concept-diagram">
                <div class="diagram-title">2. Resource Allocation Graph (RAG)</div>
                <div class="detailed-explanation">
                    <p><strong>Purpose:</strong> Visual representation of resource allocation and requests to detect deadlocks.</p>
                    
                    <h4>ğŸ”§ Graph Components:</h4>
                    <ul>
                        <li><strong>Process Node:</strong> Circle (P1, P2, P3)</li>
                        <li><strong>Resource Node:</strong> Rectangle (R1, R2, R3)</li>
                        <li><strong>Assignment Edge:</strong> Resource â†’ Process (solid arrow)</li>
                        <li><strong>Request Edge:</strong> Process â†’ Resource (dashed arrow)</li>
                    </ul>
                    
                    <h4>ğŸ“Š Example - No Deadlock:</h4>
                    <pre class="code-block">
Resources: R1(1 instance), R2(1 instance), R3(1 instance)
Processes: P1, P2, P3

Current State:
P1 holds R1, requests R2
P2 holds R2, requests R3  
P3 holds R3

Graph:
R1 â”€â”€â†’ P1 â”„â”„â†’ R2 â”€â”€â†’ P2 â”„â”„â†’ R3 â”€â”€â†’ P3

No cycle = No deadlock
P3 can finish, release R3 to P2, then P2 releases R2 to P1
                    </pre>
                    
                    <h4>âš ï¸ Example - Deadlock Present:</h4>
                    <pre class="code-block">
Current State:
P1 holds R1, requests R2
P2 holds R2, requests R1

Graph:
    P1 â†â”€â”€ R1
    â”‚       â†‘
    â†“       â”‚
    R2 â”€â”€â†’ P2

Cycle detected: P1 â†’ R2 â†’ P2 â†’ R1 â†’ P1
With single instances: Cycle = Deadlock!
                    </pre>
                    
                    <h4>ğŸ” Deadlock Detection Algorithm:</h4>
                    <pre class="code-block">
1. Build Resource Allocation Graph
2. Look for cycles in the graph
3. If cycle exists with single-instance resources:
   â†’ Deadlock confirmed
4. If cycle exists with multi-instance resources:
   â†’ Run Banker's algorithm to check
5. If no cycle:
   â†’ No deadlock
                    </pre>
                </div>
            </div>

            <div class="concept-diagram">
                <div class="diagram-title">3. Deadlock Prevention</div>
                <div class="detailed-explanation">
                    <p><strong>Strategy:</strong> Eliminate at least one of the four Coffman conditions to make deadlock impossible.</p>
                    
                    <h4>1ï¸âƒ£ Eliminate Mutual Exclusion:</h4>
                    <p><strong>Approach:</strong> Make resources shareable when possible</p>
                    <pre class="code-block">
Examples:
âœ… Read-only files: Multiple processes can read
âœ… Spooling: Print jobs queued, not direct printer access
âŒ Not always possible: Some resources are inherently exclusive
   (e.g., write access to files, hardware devices)
                    </pre>
                    
                    <h4>2ï¸âƒ£ Eliminate Hold and Wait:</h4>
                    <p><strong>Approach:</strong> Require processes to request all resources at once</p>
                    <pre class="code-block">
Protocol 1 - All or Nothing:
Process must request ALL needed resources before starting
If any resource unavailable, wait without holding any

Process P1:
request(Scanner, Printer, Disk)  // Request all at once
if (all_available) {
    // Use all resources
    release(Scanner, Printer, Disk)
}

Disadvantages:
- Low resource utilization
- Starvation possible
- Hard to predict all needed resources
                    </pre>
                    
                    <h4>3ï¸âƒ£ Eliminate No Preemption:</h4>
                    <p><strong>Approach:</strong> Allow forcible resource removal</p>
                    <pre class="code-block">
Protocol:
If process P1 holds resources and requests unavailable resource:
1. Preempt all resources from P1
2. Add preempted resources to P1's wait list
3. P1 restarts only when it can get all resources

Example:
P1 holds Scanner, requests Printer (held by P2)
â†’ Preempt Scanner from P1
â†’ P1 waits for both Scanner and Printer
â†’ When both available, P1 restarts

Works for: CPU, memory pages
Doesn't work for: Printers, mutex locks
                    </pre>
                    
                    <h4>4ï¸âƒ£ Eliminate Circular Wait:</h4>
                    <p><strong>Approach:</strong> Impose total ordering on resource types</p>
                    <pre class="code-block">
Resource Ordering Example:
R1 = Scanner (priority 1)
R2 = Printer (priority 2)  
R3 = Disk (priority 3)

Rule: Processes must request resources in increasing order

Correct:
P1: request(R1), then request(R2), then request(R3)

Incorrect:
P2: request(R3), then request(R1)  // Violates ordering

Why it works:
If all processes follow ordering, no cycle can form
Proof: Assume cycle P1â†’R_iâ†’P2â†’R_jâ†’...â†’P1â†’R_k
Since P1 requests R_i and later P1 gets R_k, we need i < k
But cycle implies k < i (contradiction!)
                    </pre>
                </div>
            </div>

            <div class="concept-diagram">
                <div class="diagram-title">4. Deadlock Avoidance - Banker's Algorithm</div>
                <div class="detailed-explanation">
                    <p><strong>Strategy:</strong> Dynamically examine resource allocation to ensure system never enters unsafe state.</p>
                    
                    <h4>ğŸ¦ Banking Analogy:</h4>
                    <p>A bank has limited cash but promises to lend money to customers. The bank must ensure it can satisfy all customers' maximum demands, even in worst-case scenario.</p>
                    
                    <h4>ğŸ”§ Key Concepts:</h4>
                    <ul>
                        <li><strong>Safe State:</strong> System can allocate resources to all processes in some order</li>
                        <li><strong>Unsafe State:</strong> No guarantee that all processes can complete</li>
                        <li><strong>Safe Sequence:</strong> Order in which processes can complete</li>
                    </ul>
                    
                    <h4>ğŸ“Š Data Structures:</h4>
                    <pre class="code-block">
n = number of processes
m = number of resource types

Available[m]: Available instances of each resource
Max[n][m]: Maximum demand of each process  
Allocation[n][m]: Currently allocated resources
Need[n][m]: Remaining need = Max - Allocation
                    </pre>
                    
                    <h4>ğŸ” Safety Algorithm:</h4>
                    <pre class="code-block">
1. Initialize Work = Available, Finish[i] = false for all i
2. Find process Pi such that:
   - Finish[i] == false
   - Need[i] <= Work
3. If found:
   - Work = Work + Allocation[i]
   - Finish[i] = true
   - Go to step 2
4. If all Finish[i] == true: SAFE
   Else: UNSAFE
                    </pre>
                    
                    <h4>ğŸ“‹ Complete Example:</h4>
                    <pre class="code-block">
3 processes (P0, P1, P2), 3 resource types (A, B, C)
Total resources: A=10, B=5, C=7

Current state:
Process | Allocation | Max | Need
        | A B C      |A B C| A B C
P0      | 0 1 0      |7 5 3| 7 4 3
P1      | 2 0 0      |3 2 2| 1 2 2  
P2      | 3 0 2      |9 0 2| 6 0 0

Available: A=3, B=3, C=2 (Total - Allocated)

Safety Check:
Work = [3,3,2], Finish = [F,F,F]

Step 1: Check P0: Need[0]=[7,4,3] > Work=[3,3,2] âŒ
Step 2: Check P1: Need[1]=[1,2,2] <= Work=[3,3,2] âœ…
        Work = [3,3,2] + [2,0,0] = [5,3,2]
        Finish[1] = true

Step 3: Check P0: Need[0]=[7,4,3] > Work=[5,3,2] âŒ  
Step 4: Check P2: Need[2]=[6,0,0] > Work=[5,3,2] âŒ

No process can proceed â†’ UNSAFE STATE!
                    </pre>
                    
                    <h4>âœ… Resource Request Algorithm:</h4>
                    <pre class="code-block">
When process Pi requests Request[m]:

1. Check if Request <= Need[i]
   If not: Error (requesting more than declared max)

2. Check if Request <= Available  
   If not: Wait (resources not available)

3. Simulate allocation:
   Available = Available - Request
   Allocation[i] = Allocation[i] + Request
   Need[i] = Need[i] - Request

4. Run safety algorithm
   If safe: Grant request
   If unsafe: Rollback and make process wait
                    </pre>
                </div>
            </div>

            <div class="concept-diagram">
                <div class="diagram-title">5. Deadlock Detection and Recovery</div>
                <div class="detailed-explanation">
                    <p><strong>Strategy:</strong> Allow deadlocks to occur, detect them, and recover.</p>
                    
                    <h4>ğŸ” Detection Algorithm:</h4>
                    <pre class="code-block">
Single Instance Resources:
- Use Resource Allocation Graph
- Look for cycles using DFS
- Cycle = Deadlock

Multiple Instance Resources:
- Use modified Banker's algorithm
- Similar to safety algorithm but different logic
                    </pre>
                    
                    <h4>ğŸ“Š Detection Algorithm (Multiple Instances):</h4>
                    <pre class="code-block">
Data structures:
Available[m]: Available resources
Allocation[n][m]: Current allocation
Request[n][m]: Current requests

Algorithm:
1. Work = Available, Finish[i] = false
2. Find process Pi such that:
   - Finish[i] == false  
   - Request[i] <= Work
3. If found:
   - Work = Work + Allocation[i]
   - Finish[i] = true
   - Go to step 2
4. If Finish[i] == false for some i:
   - Pi is deadlocked
                    </pre>
                    
                    <h4>â° When to Run Detection:</h4>
                    <ul>
                        <li><strong>Every resource request:</strong> High overhead, immediate detection</li>
                        <li><strong>Periodically:</strong> Balanced approach</li>
                        <li><strong>When CPU utilization drops:</strong> Indicates possible deadlock</li>
                    </ul>
                    
                    <h4>ğŸ”§ Recovery Methods:</h4>
                    
                    <h5>1ï¸âƒ£ Process Termination:</h5>
                    <pre class="code-block">
Option A: Terminate ALL deadlocked processes
- Simple but expensive
- All work lost

Option B: Terminate processes one by one
- Check after each termination if deadlock resolved
- Less expensive but more complex

Selection criteria for termination:
- Process priority
- Computation time used
- Resources held
- Resources needed to complete
- Interactive vs batch process
                    </pre>
                    
                    <h5>2ï¸âƒ£ Resource Preemption:</h5>
                    <pre class="code-block">
Steps:
1. Select victim process
2. Rollback process to safe state
3. Preempt resources from victim
4. Give resources to other processes

Issues:
- Starvation: Same process always selected
- Rollback: How far to rollback?
- Cost: Overhead of preemption

Solution for starvation:
Include number of preemptions in selection criteria
                    </pre>
                    
                    <h4>ğŸ“Š Deadlock Handling Comparison:</h4>
                    <pre class="code-block">
Method      | Overhead | Throughput | Response Time
Prevention  | High     | Low        | High
Avoidance   | Medium   | Medium     | Medium  
Detection   | Low      | High       | Low (until deadlock)
Ignore      | None     | Highest    | Lowest (until deadlock)

Real Systems:
- Windows: Mostly ignores, some prevention
- Linux: Mostly ignores, some prevention  
- Databases: Detection and recovery
- Real-time: Prevention and avoidance
                    </pre>
                </div>
            </div>

            <div class="concept-diagram">
                <div class="diagram-title">6. Practical Examples and Case Studies</div>
                <div class="detailed-explanation">
                    <h4>ğŸ’» Database Deadlock Example:</h4>
                    <pre class="code-block">
Transaction T1:          Transaction T2:
BEGIN                    BEGIN
LOCK TABLE A             LOCK TABLE B
UPDATE A SET x=1         UPDATE B SET y=2
LOCK TABLE B â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ LOCK TABLE A â† DEADLOCK!
UPDATE B SET z=3         UPDATE A SET w=4
COMMIT                   COMMIT

Database Solution:
- Timeout-based detection
- Automatic rollback of one transaction
- Retry mechanism
                    </pre>
                    
                    <h4>ğŸ”’ Mutex Deadlock in C++:</h4>
                    <pre class="code-block">
// Problematic code
std::mutex m1, m2;

Thread 1:                Thread 2:
m1.lock();              m2.lock();
m2.lock(); // Waits     m1.lock(); // Waits
// ... work              // ... work
m2.unlock();            m1.unlock();
m1.unlock();            m2.unlock();

// Solution: Consistent ordering
Thread 1:                Thread 2:
m1.lock();              m1.lock();  // Same order
m2.lock();              m2.lock();
// ... work              // ... work  
m2.unlock();            m2.unlock();
m1.unlock();            m1.unlock();
                    </pre>
                    
                    <h4>ğŸŒ Distributed System Deadlock:</h4>
                    <pre class="code-block">
Node A holds Resource X, requests Resource Y (on Node B)
Node B holds Resource Y, requests Resource X (on Node A)

Challenges:
- No global state knowledge
- Network delays and failures
- Distributed detection algorithms needed

Solutions:
- Distributed deadlock detection algorithms
- Timeout-based approaches
- Hierarchical resource ordering
                    </pre>
                    
                    <h4>ğŸ¯ Best Practices:</h4>
                    <ul>
                        <li><strong>Lock Ordering:</strong> Always acquire locks in same order</li>
                        <li><strong>Timeout:</strong> Use timeouts for lock acquisition</li>
                        <li><strong>Lock-Free Programming:</strong> Use atomic operations when possible</li>
                        <li><strong>Minimize Lock Scope:</strong> Hold locks for shortest time possible</li>
                        <li><strong>Avoid Nested Locks:</strong> Reduce complexity</li>
                    </ul>
                </div>
            </div>
        </div>
    </div>

    <div id="io-filesystem" class="modal">
        <div class="modal-content">
            <span class="close" onclick="closeModal('io-filesystem')">&times;</span>
            <h2>ğŸ“ I/O & File Systems - Complete Guide</h2>
            
            <div class="concept-diagram">
                <div class="diagram-title">I/O Subsystem Introduction</div>
                <div class="detailed-explanation">
                    <p><strong>Purpose:</strong> The I/O subsystem manages communication between the computer and external devices, providing a uniform interface for diverse hardware.</p>
                    
                    <h4>ğŸ¯ Key Objectives:</h4>
                    <ul>
                        <li><strong>Device Independence:</strong> Applications don't need to know hardware details</li>
                        <li><strong>Uniform Interface:</strong> Consistent API for different devices</li>
                        <li><strong>Error Handling:</strong> Manage device failures gracefully</li>
                        <li><strong>Efficiency:</strong> Optimize data transfer and device utilization</li>
                    </ul>
                    
                    <h4>ğŸ”§ I/O Device Categories:</h4>
                    <pre class="code-block">
Block Devices:
- Transfer data in fixed-size blocks
- Examples: Hard disks, SSDs, USB drives
- Support random access
- Typical block size: 512 bytes to 4KB

Character Devices:
- Transfer data as stream of characters
- Examples: Keyboards, mice, serial ports
- Sequential access only
- Variable data rates

Network Devices:
- Special category for network communication
- Examples: Ethernet cards, WiFi adapters
- Packet-based communication
                    </pre>
                </div>
            </div>

            <div class="concept-diagram">
                <div class="diagram-title">1. I/O Subsystem Architecture</div>
                <div class="detailed-explanation">
                    <p><strong>Layered Architecture:</strong> Multiple layers provide abstraction and functionality.</p>
                    
                    <h4>ğŸ—ï¸ I/O Software Layers:</h4>
                    <pre class="code-block">
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â† User Applications
â”‚    User-Level I/O       â”‚   (printf, scanf, file operations)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Device-Independent     â”‚ â† OS I/O System
â”‚     Software            â”‚   (buffering, caching, spooling)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚    Device Drivers       â”‚ â† Hardware-Specific
â”‚                         â”‚   (device control, status checking)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Interrupt Handlers     â”‚ â† Hardware Interface
â”‚                         â”‚   (interrupt processing)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚       Hardware          â”‚ â† Physical Devices
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    </pre>
                    
                    <h4>ğŸ”„ I/O Request Flow:</h4>
                    <pre class="code-block">
1. Application calls I/O function (e.g., read())
2. System call interface validates parameters
3. Device-independent layer handles buffering
4. Device driver translates to hardware commands
5. Hardware performs actual I/O operation
6. Interrupt signals completion
7. Interrupt handler processes completion
8. Data/status returned to application
                    </pre>
                    
                    <h4>ğŸ’¾ Buffering Strategies:</h4>
                    <pre class="code-block">
No Buffering:
- Direct transfer between device and user space
- Simple but inefficient
- Used for character devices

Single Buffering:
- One buffer in kernel space
- Application waits while buffer fills/empties
- Better than no buffering

Double Buffering:
- Two buffers alternate roles
- While one buffer is being filled, other is processed
- Improves throughput

Circular Buffering:
- Multiple buffers in circular arrangement
- Continuous data flow
- Used for streaming devices
                    </pre>
                    
                    <h4>ğŸ–¨ï¸ Spooling (Simultaneous Peripheral Operations On-Line):</h4>
                    <pre class="code-block">
Problem: Printer can only handle one job at a time
Solution: Spool jobs to disk, print sequentially

Process:
1. Application "prints" to spool file on disk
2. Spooling daemon manages print queue
3. Jobs printed in order (FIFO typically)
4. Multiple applications can "print" simultaneously

Benefits:
- Improved system throughput
- Better resource utilization
- Job scheduling flexibility

Example: Print spooling in Windows/Linux
                    </pre>
                </div>
            </div>

            <div class="concept-diagram">
                <div class="diagram-title">2. I/O Hardware and Techniques</div>
                <div class="detailed-explanation">
                    <h4>ğŸ”Œ I/O Hardware Components:</h4>
                    <pre class="code-block">
Device Controller:
- Hardware interface between device and computer
- Contains registers for data, status, control
- Handles low-level device operations

Device Registers:
- Data Register: Holds data being transferred
- Status Register: Shows device state (busy, ready, error)
- Control Register: Commands to device

Memory-Mapped I/O:
- Device registers mapped to memory addresses
- CPU uses regular memory instructions
- Example: mov [0x3F8], al  ; Write to serial port

Port-Mapped I/O:
- Separate address space for I/O devices
- Special I/O instructions (IN, OUT on x86)
- Example: out 0x3F8, al    ; Write to serial port
                    </pre>
                    
                    <h4>âš¡ I/O Techniques:</h4>
                    
                    <h5>1ï¸âƒ£ Programmed I/O (Polling):</h5>
                    <pre class="code-block">
Process:
1. CPU initiates I/O operation
2. CPU continuously checks device status
3. When ready, CPU transfers data
4. Repeat until operation complete

Example Code:
while (device_status != READY) {
    // Busy wait - CPU does nothing useful
}
transfer_data();

Advantages: Simple, no special hardware needed
Disadvantages: CPU waste, poor for slow devices
                    </pre>
                    
                    <h5>2ï¸âƒ£ Interrupt-Driven I/O:</h5>
                    <pre class="code-block">
Process:
1. CPU initiates I/O operation
2. CPU continues other work
3. Device sends interrupt when ready
4. CPU handles interrupt, transfers data

Interrupt Handler:
save_cpu_state();
if (device_ready()) {
    transfer_data();
    signal_completion();
}
restore_cpu_state();

Advantages: CPU not wasted, good responsiveness
Disadvantages: Interrupt overhead, still CPU involvement
                    </pre>
                    
                    <h5>3ï¸âƒ£ Direct Memory Access (DMA):</h5>
                    <pre class="code-block">
Process:
1. CPU sets up DMA controller
   - Source address
   - Destination address  
   - Transfer size
   - Direction (read/write)
2. DMA controller handles entire transfer
3. CPU free to do other work
4. DMA sends interrupt when complete

DMA Setup:
dma_source = buffer_address;
dma_dest = device_address;
dma_count = transfer_size;
dma_control = START | READ;

Advantages: No CPU involvement during transfer
Disadvantages: More complex hardware, bus contention
                    </pre>
                </div>
            </div>

            <div class="concept-diagram">
                <div class="diagram-title">3. File System Fundamentals</div>
                <div class="detailed-explanation">
                    <p><strong>Definition:</strong> A file system provides organized storage and retrieval of data on storage devices.</p>
                    
                    <h4>ğŸ“ File Concept:</h4>
                    <pre class="code-block">
File: Named collection of related information
- Logical unit of storage
- Abstraction over physical storage
- Persistent (survives system shutdown)

File Attributes:
- Name: Human-readable identifier
- Type: File format (text, binary, executable)
- Size: Current file size in bytes
- Location: Physical location on storage
- Protection: Access permissions
- Time stamps: Creation, modification, access
                    </pre>
                    
                    <h4>ğŸ”§ File Operations:</h4>
                    <pre class="code-block">
Basic Operations:
1. Create: Allocate space, create directory entry
2. Open: Prepare file for access, return handle
3. Read: Transfer data from file to memory
4. Write: Transfer data from memory to file
5. Seek: Move file pointer to specific position
6. Close: Release resources, update metadata
7. Delete: Remove file and free space

File Descriptor/Handle:
- Integer representing open file
- Index into system file table
- Used in all file operations after open()

Example (C):
int fd = open("file.txt", O_RDWR);
read(fd, buffer, 1024);
write(fd, data, 512);
close(fd);
                    </pre>
                    
                    <h4>ğŸ“‚ Directory Structure:</h4>
                    <pre class="code-block">
Directory: Special file containing list of files
- Maps file names to file metadata
- Organizes files hierarchically

Directory Operations:
- Create directory
- List directory contents
- Search for file
- Rename file
- Delete directory

Directory Implementation:
Linear List:
- Simple array of file entries
- Sequential search (slow for large directories)

Hash Table:
- Hash file name to get index
- Faster search, more complex
- Collision handling needed

B-Tree:
- Balanced tree structure
- Fast search, insertion, deletion
- Used in modern file systems
                    </pre>
                </div>
            </div>

            <div class="concept-diagram">
                <div class="diagram-title">4. File System Structure</div>
                <div class="detailed-explanation">
                    <p><strong>Layered Design:</strong> File system organized in multiple layers for modularity and efficiency.</p>
                    
                    <h4>ğŸ—ï¸ File System Layers:</h4>
                    <pre class="code-block">
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Application Layer     â”‚ â† User programs
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Logical File System   â”‚ â† File operations, directory management
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  File Organization      â”‚ â† File allocation, free space management
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Basic File System     â”‚ â† Block I/O, buffering
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   I/O Control          â”‚ â† Device drivers
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚      Hardware          â”‚ â† Storage devices
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    </pre>
                    
                    <h4>ğŸ’¾ On-Disk File System Structure:</h4>
                    <pre class="code-block">
Typical Disk Layout:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Boot Block  â”‚ Super Block â”‚ Inode Table â”‚ Data Blocks â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Boot Block (Block 0):
- Contains boot loader program
- Loaded by BIOS/UEFI to start OS
- Usually 512 bytes or 1 sector

Super Block:
- File system metadata
- Total blocks, free blocks
- Inode table size and location
- Block size, file system type
- Magic number for identification

Inode Table:
- Array of inodes (index nodes)
- Each inode describes one file
- Contains file metadata and block pointers
- Fixed size, allocated at format time

Data Blocks:
- Actual file content
- Directory data
- Free space for new files
                    </pre>
                    
                    <h4>ğŸ“‹ Inode Structure (Unix-style):</h4>
                    <pre class="code-block">
Inode Contents:
- File type and permissions (16 bits)
- Owner user ID (16 bits)
- Owner group ID (16 bits)  
- File size (32/64 bits)
- Time stamps (creation, modification, access)
- Link count (number of directory entries)
- Block pointers (direct and indirect)

Block Pointers:
- 12 direct pointers â†’ point to data blocks
- 1 single indirect â†’ points to block of pointers
- 1 double indirect â†’ points to block of single indirect
- 1 triple indirect â†’ points to block of double indirect

Maximum File Size Calculation:
Block size = 4KB, Pointer size = 4 bytes
Direct: 12 Ã— 4KB = 48KB
Single indirect: (4KB/4) Ã— 4KB = 4MB
Double indirect: (4KB/4)Â² Ã— 4KB = 4GB
Triple indirect: (4KB/4)Â³ Ã— 4KB = 4TB
Total: ~4TB maximum file size
                    </pre>
                </div>
            </div>

            <div class="concept-diagram">
                <div class="diagram-title">5. File Allocation Methods</div>
                <div class="detailed-explanation">
                    <p><strong>Problem:</strong> How to allocate disk blocks to files efficiently?</p>
                    
                    <h4>1ï¸âƒ£ Contiguous Allocation:</h4>
                    <pre class="code-block">
Concept: Store file in consecutive disk blocks

Directory Entry:
File Name | Start Block | Length
file1.txt |     100     |   5
file2.txt |     105     |   3

Disk Layout:
[100][101][102][103][104] â† file1.txt
[105][106][107]           â† file2.txt

Advantages:
âœ… Simple implementation
âœ… Fast sequential access
âœ… Minimal seek time
âœ… Good for read-only files

Disadvantages:
âŒ External fragmentation
âŒ File size must be known in advance
âŒ Difficult to grow files
âŒ Compaction needed periodically

Use Cases:
- CD-ROMs, DVDs (read-only)
- Embedded systems with known file sizes
                    </pre>
                    
                    <h4>2ï¸âƒ£ Linked Allocation:</h4>
                    <pre class="code-block">
Concept: File stored as linked list of blocks

Directory Entry:
File Name | Start Block | End Block
file1.txt |     100     |    104

Block Structure:
Block 100: [Data][Pointer to 102]
Block 102: [Data][Pointer to 107]  
Block 107: [Data][Pointer to 201]
Block 201: [Data][NULL]

File Allocation Table (FAT):
Block | Next Block
100   |    102
102   |    107
107   |    201
201   |    EOF

Advantages:
âœ… No external fragmentation
âœ… Files can grow dynamically
âœ… No need to declare file size

Disadvantages:
âŒ Poor random access (must follow chain)
âŒ Extra space for pointers
âŒ Reliability issues (broken chain)
âŒ No locality of reference

Improvements:
- Cluster allocation (group of blocks)
- File Allocation Table (FAT file system)
                    </pre>
                    
                    <h4>3ï¸âƒ£ Indexed Allocation:</h4>
                    <pre class="code-block">
Concept: Index block contains pointers to data blocks

Directory Entry:
File Name | Index Block
file1.txt |     200

Index Block 200:
[Pointer to 100]
[Pointer to 102]
[Pointer to 107]
[Pointer to 201]
[NULL]
[NULL]
...

Data Blocks:
Block 100: [File Data]
Block 102: [File Data]
Block 107: [File Data]
Block 201: [File Data]

Advantages:
âœ… Fast random access
âœ… No external fragmentation
âœ… Dynamic file growth
âœ… Easy to find free blocks

Disadvantages:
âŒ Index block overhead
âŒ Small files waste space
âŒ Large files need multiple index blocks

Multi-level Indexing:
- Single indirect: Index block points to data
- Double indirect: Index block points to index blocks
- Triple indirect: Three levels of indirection
- Used in Unix inode system
                    </pre>
                    
                    <h4>ğŸ“Š Allocation Method Comparison:</h4>
                    <pre class="code-block">
Method      | Sequential | Random | Fragmentation | Growth
Contiguous  |   Fast     |  Fast  |     High      |  Poor
Linked      |   Good     |  Slow  |     None      |  Good
Indexed     |   Good     |  Fast  |     Low       |  Good

Real-World Usage:
- FAT32: Modified linked allocation
- NTFS: Indexed allocation with extents
- ext4: Indexed allocation with extents
- ZFS: Copy-on-write with dynamic allocation
                    </pre>
                </div>
            </div>

            <div class="concept-diagram">
                <div class="diagram-title">6. Free Space Management</div>
                <div class="detailed-explanation">
                    <p><strong>Problem:</strong> How to keep track of free disk blocks efficiently?</p>
                    
                    <h4>1ï¸âƒ£ Bit Vector (Bitmap):</h4>
                    <pre class="code-block">
Concept: One bit per block (0=free, 1=allocated)

Example (16 blocks):
Blocks: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
Bitmap: 1 1 1 0 0 1 1 0 0 0  1  0  0  1  1  1

Free blocks: 3, 4, 7, 8, 9, 11, 12

Finding Free Block:
for (i = 0; i < total_blocks; i++) {
    if (bitmap[i/8] & (1 << (i%8)) == 0) {
        return i;  // Found free block
    }
}

Advantages:
âœ… Simple and efficient
âœ… Easy to find contiguous free blocks
âœ… Compact representation

Disadvantages:
âŒ Bitmap size grows with disk size
âŒ Must be kept in memory for efficiency
âŒ Bit manipulation overhead

Space Overhead:
1TB disk, 4KB blocks = 256M blocks
Bitmap size = 256M bits = 32MB
                    </pre>
                    
                    <h4>2ï¸âƒ£ Linked List:</h4>
                    <pre class="code-block">
Concept: Link all free blocks together

Free List Head: Block 100

Block 100: [Pointer to 102][Free Space]
Block 102: [Pointer to 107][Free Space]
Block 107: [Pointer to 201][Free Space]
Block 201: [NULL][Free Space]

Allocation:
1. Remove first block from free list
2. Update free list head
3. Return block to requester

Deallocation:
1. Add block to front of free list
2. Update pointers

Advantages:
âœ… No space wasted on bitmap
âœ… Works well when disk nearly full

Disadvantages:
âŒ Cannot find contiguous blocks easily
âŒ Disk I/O needed to traverse list
âŒ No random access to free blocks
                    </pre>
                    
                    <h4>3ï¸âƒ£ Grouping:</h4>
                    <pre class="code-block">
Concept: Store addresses of free blocks in free blocks

First Free Block contains:
- Addresses of n-1 free blocks
- Address of next group block

Example:
Block 100: [102, 107, 201, 205, 300] â† 4 free blocks + next group
Block 300: [301, 305, 310, 315, 400] â† 4 free blocks + next group
Block 400: [401, 405, 410, 415, NULL] â† 4 free blocks + end

Advantages:
âœ… Fast allocation of multiple blocks
âœ… Reduces disk I/O
âœ… Good for large file allocation

Disadvantages:
âŒ Complex implementation
âŒ Fragmentation of free space info
                    </pre>
                    
                    <h4>4ï¸âƒ£ Counting:</h4>
                    <pre class="code-block">
Concept: Store address and count of contiguous free blocks

Free Space Table:
Start Block | Count
    100     |   5    â† Blocks 100-104 free
    200     |   3    â† Blocks 200-202 free
    500     |   10   â† Blocks 500-509 free

Allocation Algorithm:
1. Find entry with sufficient count
2. Allocate from beginning of range
3. Update count and start address
4. Remove entry if count becomes 0

Advantages:
âœ… Efficient for contiguous allocation
âœ… Compact representation
âœ… Fast allocation of large files

Disadvantages:
âŒ Complex when blocks scattered
âŒ Fragmentation reduces efficiency
                    </pre>
                </div>
            </div>

            <div class="concept-diagram">
                <div class="diagram-title">7. File System Performance and Reliability</div>
                <div class="detailed-explanation">
                    <h4>âš¡ Performance Optimization:</h4>
                    
                    <h5>1ï¸âƒ£ Caching:</h5>
                    <pre class="code-block">
Buffer Cache:
- Keep frequently used blocks in memory
- Reduce disk I/O operations
- LRU replacement policy

Directory Caching:
- Cache directory entries
- Speed up file name lookups
- Reduce directory traversal time

Metadata Caching:
- Cache inodes and file attributes
- Avoid repeated disk reads
- Update cache on modifications
                    </pre>
                    
                    <h5>2ï¸âƒ£ Read-Ahead:</h5>
                    <pre class="code-block">
Sequential Read-Ahead:
- Predict next blocks to be read
- Pre-load blocks into cache
- Improve sequential access performance

Example:
Application reads block 100
System pre-loads blocks 101, 102, 103
Next read hits cache instead of disk
                    </pre>
                    
                    <h5>3ï¸âƒ£ Write Optimization:</h5>
                    <pre class="code-block">
Write-Back Caching:
- Buffer writes in memory
- Write to disk later (lazy writing)
- Combine multiple writes to same block

Write-Through Caching:
- Write to disk immediately
- Slower but more reliable
- Used for critical data

Journaling:
- Log changes before applying them
- Enables fast recovery after crash
- Used in ext3, ext4, NTFS
                    </pre>
                    
                    <h4>ğŸ›¡ï¸ Reliability and Recovery:</h4>
                    
                    <h5>1ï¸âƒ£ File System Consistency:</h5>
                    <pre class="code-block">
Consistency Problems:
- System crash during file operation
- Inconsistent metadata (inodes, free lists)
- Lost blocks, duplicate allocation

File System Check (fsck):
1. Check superblock for reasonableness
2. Check free block list consistency
3. Check inode consistency
4. Check directory structure
5. Fix inconsistencies found

Example Inconsistencies:
- Block marked free but allocated to file
- Inode link count doesn't match directory entries
- Directory points to invalid inode
                    </pre>
                    
                    <h5>2ï¸âƒ£ Journaling File Systems:</h5>
                    <pre class="code-block">
Journal Structure:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Journal   â”‚ Superblock  â”‚ Data Blocks â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Write Process:
1. Write operation details to journal
2. Mark journal entry as complete
3. Apply changes to actual file system
4. Mark journal entry as applied
5. Remove journal entry

Recovery Process:
1. Check journal for incomplete operations
2. Replay completed but unapplied operations
3. Discard incomplete operations
4. File system is consistent

Types of Journaling:
- Metadata only: Journal metadata changes
- Full journaling: Journal data and metadata
- Ordered: Write data before metadata
                    </pre>
                    
                    <h4>ğŸ”’ File System Security:</h4>
                    <pre class="code-block">
Access Control:
- User/Group/Other permissions
- Read/Write/Execute bits
- Access Control Lists (ACLs)

Example (Unix permissions):
-rwxr-xr--  1 user group 1024 Jan 1 12:00 file.txt
â”‚â”‚â”‚â”‚â”‚â”‚â”‚â”‚â”‚
â”‚â”‚â”‚â”‚â”‚â”‚â”‚â””â”€ Other: read
â”‚â”‚â”‚â”‚â”‚â””â”€â”€â”€â”€ Other: no write
â”‚â”‚â”‚â”‚â””â”€â”€â”€â”€â”€ Other: no execute
â”‚â”‚â”‚â””â”€â”€â”€â”€â”€â”€ Group: read
â”‚â”‚â””â”€â”€â”€â”€â”€â”€â”€ Group: no write
â”‚â””â”€â”€â”€â”€â”€â”€â”€â”€ Group: execute
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€ User: read, write, execute

Encryption:
- File-level encryption
- File system-level encryption
- Full disk encryption
- Key management
                    </pre>
                </div>
            </div>

            <div class="concept-diagram">
                <div class="diagram-title">8. Modern File Systems</div>
                <div class="detailed-explanation">
                    <h4>ğŸ”„ Copy-on-Write File Systems:</h4>
                    <pre class="code-block">
ZFS (Zettabyte File System):
- Never overwrites data in place
- Creates new copy when modifying
- Atomic transactions
- Built-in compression and deduplication
- Snapshots and clones

BTRFS (B-tree File System):
- Copy-on-write semantics
- Subvolumes and snapshots
- Built-in RAID support
- Online defragmentation
- Checksumming for data integrity
                    </pre>
                    
                    <h4>ğŸ“± Flash-Based File Systems:</h4>
                    <pre class="code-block">
SSD Characteristics:
- No mechanical parts (no seek time)
- Limited write/erase cycles
- Wear leveling needed
- Different performance for read/write

TRIM Command:
- Tells SSD which blocks are no longer used
- Enables garbage collection
- Improves performance and lifespan

F2FS (Flash-Friendly File System):
- Designed specifically for flash storage
- Log-structured approach
- Efficient garbage collection
- Wear leveling support
                    </pre>
                    
                    <h4>â˜ï¸ Distributed File Systems:</h4>
                    <pre class="code-block">
Network File System (NFS):
- Access remote files over network
- Transparent to applications
- Stateless protocol
- Caching for performance

Google File System (GFS):
- Designed for large distributed systems
- Handles component failures gracefully
- Optimized for large files
- Master-slave architecture

Hadoop Distributed File System (HDFS):
- Designed for big data processing
- High fault tolerance
- Optimized for streaming access
- Write-once, read-many model
                    </pre>
                    
                    <h4>ğŸ“Š File System Comparison:</h4>
                    <pre class="code-block">
File System | Max File Size | Max Volume | Features
FAT32       |     4GB       |    2TB     | Simple, compatible
NTFS        |    16TB       |   256TB    | Journaling, compression
ext4        |    16TB       |    1EB     | Journaling, extents
ZFS         |    16EB       |   256ZB    | COW, snapshots, RAID
BTRFS       |    16EB       |   16EB     | COW, subvolumes
APFS        |     8EB       |    8EB     | COW, encryption, clones

EB = Exabyte (10^18 bytes)
ZB = Zettabyte (10^21 bytes)
                    </pre>
                </div>
            </div>
        </div>
    </div>

    <script>
        function openModal(modalId) {
            document.getElementById(modalId).style.display = 'block';
            document.body.style.overflow = 'hidden';
        }

        function closeModal(modalId) {
            document.getElementById(modalId).style.display = 'none';
            document.body.style.overflow = 'auto';
        }

        // Close modal when clicking outside of it
        window.onclick = function(event) {
            const modals = document.querySelectorAll('.modal');
            modals.forEach(modal => {
                if (event.target === modal) {
                    modal.style.display = 'none';
                    document.body.style.overflow = 'auto';
                }
            });
        }

        // Close modal with Escape key
        document.addEventListener('keydown', function(event) {
            if (event.key === 'Escape') {
                const modals = document.querySelectorAll('.modal');
                modals.forEach(modal => {
                    if (modal.style.display === 'block') {
                        modal.style.display = 'none';
                        document.body.style.overflow = 'auto';
                    }
                });
            }
        });

        // Add smooth scrolling for modal content
        document.querySelectorAll('.modal-content').forEach(content => {
            content.style.scrollBehavior = 'smooth';
        });
    </script>
</body>
</html>